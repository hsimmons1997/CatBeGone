{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing motion detection to find Kodak in a video frame\n",
    "Once i have code that can detect Kodak in a video, I'll connect it to the camera. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "import subprocess\n",
    "import IPython.display as ipd\n",
    "\n",
    "import torch\n",
    "from torchvision import models\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_input = \"test1.MOV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['ffmpeg', '-i', 'test1.MOV', '-qscale', '0', 'test1.mp4', '-loglevel', 'quiet'], returncode=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting from .mov to .mp4 and removing the last second of the video\n",
    "subprocess.run(['ffmpeg', '-i', test1_input, '-qscale', '0', 'test1.mp4', '-loglevel', 'quiet', ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeing the video\n",
    "ipd.Video('test1.mp4', width = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ok, lets do the motion detector now\n",
    "If a moving object appears in 5 consecutive frames, I want the box to be passed to my pre-trained kodak_detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normalize the box before sending it to my model\n",
    "def preprocess_frame(frame):\n",
    "    resized_frame = cv2.resize(frame, (224, 224))\n",
    "    normalized_frame = resized_frame / 255\n",
    "    processed = np.expand_dims(normalized_frame, axis = 0)\n",
    "    return processed\n",
    "\n",
    "def is_it_kodak(frame):\n",
    "    processed_frame = preprocess_frame(frame)\n",
    "    prediction = model.predict(processed_frame)\n",
    "    pos_or_neg = np.argmax(prediction, axis = 1)[0] == 1\n",
    "    return pos_or_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing for the video\n",
    "class_names = [0, 1]\n",
    "background = None\n",
    "motion_frames = 0\n",
    "consecutive_frames = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining model architecture\n",
    "model = models.resnet18()\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading model weights\n",
    "model.load_state_dict(torch.load('is_that_kodak.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = cv2.VideoCapture('test1.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ResNet' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m motion_frames \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m consecutive_frames:\n\u001b[1;32m     44\u001b[0m     frame_to_identify \u001b[38;5;241m=\u001b[39m frame[y:y \u001b[38;5;241m+\u001b[39m h, x:x \u001b[38;5;241m+\u001b[39m w]\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_it_kodak(frame_to_identify):\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCAT ALERT OMG\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mimwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdetected_cat.jpeg\u001b[39m\u001b[38;5;124m'\u001b[39m, frame_to_identify)\n",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m, in \u001b[0;36mis_it_kodak\u001b[0;34m(frame)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_it_kodak\u001b[39m(frame):\n\u001b[1;32m      9\u001b[0m     processed_frame \u001b[38;5;241m=\u001b[39m preprocess_frame(frame)\n\u001b[0;32m---> 10\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(processed_frame)\n\u001b[1;32m     11\u001b[0m     pos_or_neg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(prediction, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pos_or_neg\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ResNet' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Take in first frame, convert it to gray scale, then blur it\n",
    "    check, frame = test1.read()\n",
    "    if not check:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (41, 41), 0)\n",
    "\n",
    "    # If there is not yet a background, make one\n",
    "    if background is None:\n",
    "        background = gray\n",
    "        continue\n",
    "    \n",
    "    # Finding the difference between background and current frame\n",
    "    diff_frame = cv2.absdiff(background, gray)\n",
    "\n",
    "    # If the difference is greater than 50, make a binary mask where the motion is white\n",
    "    threshold = cv2.threshold(diff_frame, 100, 255, cv2.THRESH_BINARY)[1]\n",
    "    threshold = cv2.dilate(threshold, None, iterations = 2)\n",
    "\n",
    "    # Given motion, find the contours of the object\n",
    "    contours, _ = cv2.findContours(threshold, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    motion_detected = False\n",
    "\n",
    "    # Making sure the object isn't too big\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) < 10000:\n",
    "            continue\n",
    "        motion = 1\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "        # Drawing a box around the moving object\n",
    "        cv2.rectangle(frame, (x - 20, y - 20), (x + w + 20, y + h + 20), (0, 0, 255), 3)\n",
    "        motion_detected = True\n",
    "    \n",
    "    if motion_detected:\n",
    "        motion_frames += 1\n",
    "    else:\n",
    "        motion_frames = 0\n",
    "\n",
    "    # If motion is detected in 5 consecutive frames, save the frame and send to model\n",
    "    if motion_frames >= consecutive_frames:\n",
    "        frame_to_identify = frame[y:y + h, x:x + w]\n",
    "        if is_it_kodak(frame_to_identify):\n",
    "            print(\"CAT ALERT OMG\")\n",
    "            cv2.imwrite('detected_cat.jpeg', frame_to_identify)\n",
    "        motion_frames = 0\n",
    "    \n",
    "    # Displaying image in gray_scale \n",
    "    cv2.imshow(\"Gray Frame\", gray) \n",
    "  \n",
    "    # Displaying the difference in currentframe to \n",
    "    # the staticframe(very first_frame) \n",
    "    cv2.imshow(\"Difference Frame\", diff_frame) \n",
    "  \n",
    "    # Displaying the black and white image in which if \n",
    "    # intensity difference greater than 30 it will appear white \n",
    "    cv2.imshow(\"Threshold Frame\", threshold) \n",
    "  \n",
    "    # Displaying color frame with contour of motion of object \n",
    "    cv2.imshow(\"Color Frame\", frame) \n",
    "  \n",
    "    key = cv2.waitKey(1) \n",
    "    # if q entered whole process will stop \n",
    "    if key == ord('q'): \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
