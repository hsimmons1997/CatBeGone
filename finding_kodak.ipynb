{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing motion detection to find Kodak in a video frame\n",
    "Once i have code that can detect Kodak in a video, I'll connect it to the camera. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "import subprocess\n",
    "import IPython.display as ipd\n",
    "\n",
    "import torch\n",
    "from torchvision import models\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test1_input = \"test1.MOV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting from .mov to .mp4 and removing the last second of the video\n",
    "# subprocess.run(['ffmpeg', '-i', test1_input, '-qscale', '0', 'test1.mp4', '-loglevel', 'quiet', ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeing the video\n",
    "# ipd.Video('test1.mp4', width = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ok, lets do the motion detector now\n",
    "If a moving object appears in 5 consecutive frames, I want the box to be passed to my pre-trained kodak_detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normalize the box before sending it to my model\n",
    "def preprocess_frame(frame):\n",
    "    # Fed a frame from the video as an image\n",
    "    resized_frame = cv2.resize(frame, (224, 224))\n",
    "    normalized_frame = resized_frame / 255\n",
    "    processed = np.expand_dims(normalized_frame, axis = 0)\n",
    "    return processed\n",
    "\n",
    "def is_it_kodak(frame):\n",
    "    # processed_frame = preprocess_frame(frame)\n",
    "    resized = moveaxis(frame, 2, 0)\n",
    "    prediction = model(resized)\n",
    "    pos_or_neg = np.argmax(prediction, axis = 1)[0] == 1\n",
    "    return pos_or_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing for the video\n",
    "class_names = [0, 1]\n",
    "background = None\n",
    "motion_frames = 0\n",
    "consecutive_frames = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining model architecture\n",
    "model = models.resnet18()\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading model weights\n",
    "model.load_state_dict(torch.load('is_that_kodak.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = cv2.VideoCapture('test1.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    # Take in first frame, convert it to gray scale, then blur it\n",
    "    check, frame = test1.read()\n",
    "    if not check:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (41, 41), 0)\n",
    "\n",
    "    # If there is not yet a background, make one\n",
    "    if background is None:\n",
    "        background = gray\n",
    "        continue\n",
    "    \n",
    "    # Finding the difference between background and current frame\n",
    "    diff_frame = cv2.absdiff(background, gray)\n",
    "\n",
    "    # If the difference is greater than 50, make a binary mask where the motion is white\n",
    "    threshold = cv2.threshold(diff_frame, 100, 255, cv2.THRESH_BINARY)[1]\n",
    "    threshold = cv2.dilate(threshold, None, iterations = 2)\n",
    "\n",
    "    # Given motion, find the contours of the object\n",
    "    contours, _ = cv2.findContours(threshold, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    motion_detected = False\n",
    "\n",
    "    # Making sure the object isn't too big\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) < 10000:\n",
    "            continue\n",
    "        motion = 1\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "        # Drawing a box around the moving object\n",
    "        cv2.rectangle(frame, (x - 20, y - 20), (x + w + 20, y + h + 20), (0, 0, 255), 3)\n",
    "        motion_detected = True\n",
    "    \n",
    "    if motion_detected:\n",
    "        motion_frames += 1\n",
    "    else:\n",
    "        motion_frames = 0\n",
    "\n",
    "    # If motion is detected in 5 consecutive frames, save the frame and send to model\n",
    "    if motion_frames >= consecutive_frames:\n",
    "        frame_to_identify = frame[y:y + h, x:x + w]\n",
    "        if is_it_kodak(frame_to_identify):\n",
    "            print(\"CAT ALERT OMG\")\n",
    "            cv2.imwrite('detected_cat.jpeg', frame_to_identify)\n",
    "        motion_frames = 0\n",
    "    \n",
    "    # Displaying image in gray_scale \n",
    "    cv2.imshow(\"Gray Frame\", gray) \n",
    "  \n",
    "    # Displaying the difference in currentframe to \n",
    "    # the staticframe(very first_frame) \n",
    "    cv2.imshow(\"Difference Frame\", diff_frame) \n",
    "  \n",
    "    # Displaying the black and white image in which if \n",
    "    # intensity difference greater than 30 it will appear white \n",
    "    cv2.imshow(\"Threshold Frame\", threshold) \n",
    "  \n",
    "    # Displaying color frame with contour of motion of object \n",
    "    cv2.imshow(\"Color Frame\", frame) \n",
    "  \n",
    "    key = cv2.waitKey(1) \n",
    "    # if q entered whole process will stop \n",
    "    if key == ord('q'): \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
