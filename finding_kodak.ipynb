{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing motion detection to find Kodak in a video frame\n",
    "Once i have code that can detect Kodak in a video, I'll connect it to the camera. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from numpy import moveaxis\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "import subprocess\n",
    "import IPython.display as ipd\n",
    "\n",
    "import torch\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test1_input = \"test1.MOV\"\n",
    "# test2_in = \"test2.MOV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting from .mov to .mp4 and removing the last second of the video\n",
    "# Not needed after you do it once!\n",
    "# subprocess.run(['ffmpeg', '-i', test2_in, '-qscale', '0', 'test2.mp4', '-loglevel', 'quiet', ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ok, lets do the motion detector now\n",
    "If a moving object appears in 5 consecutive frames, I want the box to be passed to my pre-trained kodak_detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame processing to feed a frame into the CNN\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(256, antialias=True),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing for the video\n",
    "class_names = [0, 1]\n",
    "motion_frames = 0\n",
    "consecutive_frames = 20\n",
    "tracker = None\n",
    "detected = False\n",
    "triggered = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining model architecture\n",
    "model = models.resnet18()\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading model weights\n",
    "model.load_state_dict(torch.load('is_that_kodak.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_it_kodak(frame):\n",
    "    # Turning on the model\n",
    "    model.eval()\n",
    "\n",
    "    # transforming the frame\n",
    "    frame_proc = preprocess(frame)\n",
    "    squeezed = torch.unsqueeze(frame_proc, 0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction = model(squeezed)\n",
    "\n",
    "    pos_or_neg = np.argmax(prediction, axis = 1)[0] == 1\n",
    "    return pos_or_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = cv2.VideoCapture('test2.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "check, frame = test1.read()\n",
    "if not check:\n",
    "    exit()\n",
    "\n",
    "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.GaussianBlur(gray, (41, 41), 0)\n",
    "\n",
    "background = gray\n",
    "\n",
    "# Create a ROI for spray zone\n",
    "spray_zone = np.zeros_like(gray)\n",
    "im_h, im_w = gray.shape\n",
    "\n",
    "#spray zone top left\n",
    "sz_tl_x = round(0.25 * im_w)\n",
    "sz_tl_y = round(0.25 * im_h)\n",
    "\n",
    "#spray zone width and height\n",
    "sz_w = round(0.5 * im_w)\n",
    "sz_h = round(0.5 * im_h)\n",
    "\n",
    "spray_zone[sz_tl_y : sz_tl_y + sz_h, sz_tl_x : sz_tl_x + sz_w] = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAT DETECTED OMG!!!!\n",
      "Alert, alert. There is a small criminal present. Triggering deterrant system.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Take in first frame, convert it to gray scale, then blur it\n",
    "    check, frame = test1.read()\n",
    "    if not check:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (41, 41), 0)\n",
    "\n",
    "    # If we've already identified the cat, there's no need to do motion detection\n",
    "    if detected:\n",
    "        if not triggered:\n",
    "            success, box = tracker.update(frame)\n",
    "            if success:\n",
    "                (x, y, w, h) = [int(i) for i in box]\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 5)\n",
    "                top_left = (x, y)\n",
    "                bottom_right = (x + w, y + h)\n",
    "                # Calculate the coordinates of the corners of the spray zone\n",
    "                sz_top_left = (sz_tl_x, sz_tl_y)\n",
    "                sz_bottom_right = (sz_tl_x + sz_w, sz_tl_y + sz_h)\n",
    "                # Check if any of the corners of the tracking box are inside the spray zone\n",
    "                if (sz_top_left[0] < top_left[0] < sz_bottom_right[0] or\n",
    "                    sz_top_left[0] < bottom_right[0] < sz_bottom_right[0]) and \\\n",
    "                (sz_top_left[1] < top_left[1] < sz_bottom_right[1] or\n",
    "                    sz_top_left[1] < bottom_right[1] < sz_bottom_right[1]):\n",
    "                #if x < sz_tl_x + sz_w < x + w and y < sz_tl_y + sz_h < y + h:\n",
    "                    print(\"Alert, alert. There is a small criminal present. Triggering deterrant system.\")\n",
    "                    # Raspberry Pi trigger code\n",
    "                    triggered = True\n",
    "    else:\n",
    "        # If there is not yet a background, make one\n",
    "        if background is None:\n",
    "            background = gray\n",
    "            continue\n",
    "        \n",
    "        # Finding the difference between background and current frame\n",
    "        diff_frame = cv2.absdiff(background, gray)\n",
    "\n",
    "        # If the difference is greater than 50, make a binary mask where the motion is white\n",
    "        threshold = cv2.threshold(diff_frame, 100, 255, cv2.THRESH_BINARY)[1]\n",
    "        threshold = cv2.dilate(threshold, None, iterations = 2)\n",
    "\n",
    "        # Given motion, find the contours of the object\n",
    "        contours, _ = cv2.findContours(threshold, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        motion_detected = False\n",
    "\n",
    "        for contour in contours:\n",
    "            if cv2.contourArea(contour) < 10000:\n",
    "                continue\n",
    "            motion_detected = True\n",
    "            (x, y, w, h) = cv2.boundingRect(contour)\n",
    "            # Drawing a box around the moving object\n",
    "            cv2.rectangle(frame, (x - 20, y - 20), (x + w + 20, y + h + 20), (0, 0, 255), 3)\n",
    "    \n",
    "        if motion_detected:\n",
    "            motion_frames += 1\n",
    "        else:\n",
    "            motion_frames = 0\n",
    "\n",
    "        # If motion is detected in 20 consecutive frames, save the frame and send to model\n",
    "        if motion_frames >= consecutive_frames:\n",
    "            frame_to_identify = frame[y:y + h, x:x + w]\n",
    "            if is_it_kodak(frame_to_identify):\n",
    "                    print(\"CAT DETECTED OMG!!!!\")\n",
    "                    cv2.imwrite('detected_cat.png', frame_to_identify)\n",
    "                    detected = True\n",
    "                    tracker = cv2.TrackerMIL_create()\n",
    "                    tracker.init(frame, (x, y, w, h))\n",
    "  \n",
    "    cv2.rectangle(frame, (sz_tl_x, sz_tl_y), (sz_tl_x + sz_w, sz_tl_y + sz_h), (0, 255, 0), 3)\n",
    "\n",
    "    # Displaying color frame with contour of motion of object \n",
    "    cv2.imshow(\"Color Frame\", frame) \n",
    "  \n",
    "    key = cv2.waitKey(1) \n",
    "    # if q entered whole process will stop \n",
    "    if key == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
